{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect\n",
    "from langdetect import LangDetectException\n",
    "\n",
    "# Function to detect English documents\n",
    "def is_english(text):\n",
    "    try:\n",
    "        return detect(text) == 'en'\n",
    "    except LangDetectException:\n",
    "        # Handle the exception for too short texts or other issues\n",
    "        return False\n",
    "\n",
    "# Filter out non-English documents\n",
    "# english_evd_list = [doc for doc in evidence_df['evidence_text'] if is_english(doc)]\n",
    "english_evidences = {}\n",
    "for _, row in evidence_df.iterrows():\n",
    "    if is_english(row['evidence_text']):\n",
    "        english_evidences[row['evidence_id']] = row['evidence_text']\n",
    "\n",
    "import json\n",
    "with open(\"english_evidence.json\" , \"w\") as file:\n",
    "    json.dump(english_evidences, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_evidence = {}\n",
    "for evd_id, evd_text in english_evidence.items():\n",
    "    if len(evd_text.split()) < 100:\n",
    "        short_evidence[evd_id] = evd_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invert the dictionary to remove duplicates\n",
    "inverted_dict = {}\n",
    "for key, value in evidence_climate_2.items():\n",
    "    inverted_dict[value] = key  # This will overwrite the entry if the value (text) is duplicated\n",
    "\n",
    "# Optionally, invert it back if you need original format with unique texts only\n",
    "unique_evidence = {v: k for k, v in inverted_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('punkt')\n",
    "word_tokenizer = nltk.tokenize.regexp.WordPunctTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('wordnet')\n",
    "lemmatizer = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "\n",
    "def lemmatize(word):\n",
    "    lemma = lemmatizer.lemmatize(word,'v') # remove suffix \n",
    "    if lemma == word:\n",
    "        lemma = lemmatizer.lemmatize(word,'n')\n",
    "    return lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_punctuation = \"!?,.;:()\"\n",
    "english_pattern = re.compile(r'[a-zA-Z]')\n",
    "\n",
    "def preprocessing(text):\n",
    "    # lower case\n",
    "    text = text.lower()\n",
    "    tokenized_text = word_tokenizer.tokenize(text)\n",
    "    pros_tokens = []\n",
    "    for word in tokenized_text:\n",
    "        word = lemmatize(word)\n",
    "        # remove stopwords, punctuation, not English words\n",
    "        if word not in (stopwords and custom_punctuation) and english_pattern.search(word):\n",
    "            pros_tokens.append(word)\n",
    "    pros_text = \" \".join(pros_tokens)\n",
    "    return pros_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prosed_evidences = {}\n",
    "for key, value in unique_evidence.items():\n",
    "    new_text = preprocessing(value)\n",
    "    prosed_evidences[key] = new_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent Dirichlet Allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora, models\n",
    "\n",
    "# Create a dictionary representation of the documents.\n",
    "dictionary = corpora.Dictionary(prepro_evd_texts)\n",
    "# Convert dictionary into a bag-of-words corpus\n",
    "corpus = [dictionary.doc2bow(doc) for doc in prepro_evd_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train LDA model\n",
    "lda_model = models.LdaModel(corpus, num_topics=30, id2word=dictionary, passes=15)\n",
    "lda_model.save('lda_model.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = models.LdaModel.load('lda_model.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, topic in lda_model.show_topics(formatted=False, num_topics=lda_model.num_topics,num_words=20):\n",
    "    print(f\"Topic #{i}:\", [word for word, prob in topic])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Assuming `lda_model` is your trained LDA model and `corpus` is your BOW corpus\n",
    "topic_usage = defaultdict(float)\n",
    "document_count = 0\n",
    "\n",
    "for bow_doc in corpus:\n",
    "    document_count += 1\n",
    "    for topic_num, prob in lda_model.get_document_topics(bow_doc, minimum_probability=0):\n",
    "        topic_usage[topic_num] += prob\n",
    "\n",
    "# Calculate average topic usage\n",
    "for topic_num in topic_usage:\n",
    "    topic_usage[topic_num] /= document_count\n",
    "\n",
    "# Sort topics by usage\n",
    "sorted_topics = sorted(topic_usage.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print sorted topics by frequency\n",
    "for topic_num, avg_prob in sorted_topics:\n",
    "    print(f\"Topic #{topic_num} average proportion: {avg_prob}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = 0.3\n",
    "relevant_topic = []\n",
    "for topic_num, avg_prob in sorted_topics:\n",
    "    if avg_prob > 0.03:\n",
    "        relevant_topic.append(topic_num)\n",
    "relevant_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evidence_ids = list(prepro_evidence.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_climate(lda_model,corpus,topic_ids, evidence_ids, prepro_evd_texts):\n",
    "    filtered_texts = {}\n",
    "\n",
    "    for doc_id, doc_bow in enumerate(corpus):\n",
    "        doc_topics = lda_model.get_document_topics(doc_bow)\n",
    "        if any(topic[0] in topic_ids for topic in doc_topics):\n",
    "            filtered_texts[evidence_ids[doc_id]] = prepro_evd_texts[doc_id]\n",
    "\n",
    "    return filtered_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unused_topic = [1,4, 5, 10,13, 16,29]\n",
    "all_topic = list(range(0,30))\n",
    "relevant_topic = [top for top in all_topic if top not in unused_topic]\n",
    "# []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "climate_texts = is_climate(lda_model, corpus, relevant_topic ,evidence_ids, prepro_evd_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "climate_evd = {}\n",
    "for key, value in climate_texts.items():\n",
    "    climate_evd[key] = \" \".join(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = 0.3\n",
    "relevant_topic = []\n",
    "for topic_num, avg_prob in sorted_topics:\n",
    "    if avg_prob > 0.03:\n",
    "        relevant_topic.append(topic_num)\n",
    "relevant_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
