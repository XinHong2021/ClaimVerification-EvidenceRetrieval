{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from statistics import mean\n",
    "import pickle\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "pd.set_option('display.float_format', '{:.1f}'.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/macbookpro/Documents/COMP90042_NLP/Project/COMP90042_2024_Project\n"
     ]
    }
   ],
   "source": [
    "%cd /Users/macbookpro/Documents/COMP90042_NLP/Project/COMP90042_2024_Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/train-claims.json\", 'r') as file:\n",
    "    train_claims = json.load(file)\n",
    "\n",
    "with open(\"data/dev-claims.json\", 'r') as file:\n",
    "    dev_claims = json.load(file)\n",
    "\n",
    "with open(\"data/test-claims-unlabelled.json\", 'r') as file:\n",
    "    test_claims_unlabelled = json.load(file)\n",
    "\n",
    "with open(\"data/dev_pred.json\", 'r') as file:\n",
    "    dev_pred = json.load(file)\n",
    "\n",
    "with open(\"data/evidence.json\", 'r') as file:\n",
    "    evidence = json.load(file)\n",
    "\n",
    "with open(\"data/test_pred.json\", 'r') as file:\n",
    "    test_claims_pred = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_claims_dic = [{\"claim_id\": key,\n",
    "                    \"claim_text\": value[\"claim_text\"],\n",
    "                    \"claim_label\": value[\"claim_label\"],\n",
    "                    \"evidences_id\": value[\"evidences\"]} for (key,value) in train_claims.items()]\n",
    "train_claims_df = pd.json_normalize(train_claims_dic)\n",
    "\n",
    "dev_claims_dic = [{\"claim_id\": key,\n",
    "                    \"claim_text\": value[\"claim_text\"],\n",
    "                    \"claim_label\": value[\"claim_label\"],\n",
    "                    \"evidences_id\": value[\"evidences\"]} for (key,value) in dev_claims.items()]\n",
    "dev_claims_df = pd.json_normalize(dev_claims_dic)\n",
    "\n",
    "test_claims_dic = [{\"claim_id\": key,\n",
    "                    \"claim_text\": value[\"claim_text\"]} for (key,value) in test_claims_unlabelled.items()]\n",
    "test_claims_df = pd.json_normalize(test_claims_dic)\n",
    "\n",
    "evidence_dic = [{\"evidence_id\": key,\n",
    "                             \"evidence_text\": value\n",
    "                             } for (key, value) in evidence.items()]\n",
    "evidence_df = pd.json_normalize(evidence_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(columns=['claim_id','text'])\n",
    "train_y = []\n",
    "for key, value in train_claims.items():\n",
    "    row_to_add = pd.DataFrame({\n",
    "        \"claim_id\" :[key],\n",
    "        \"text\": [\"<sep>\".join([\"<cls>\" +value['claim_text']] + [evidence[evd_id] for evd_id in value['evidences']])]\n",
    "    })\n",
    "    train_df = train_df.append(row_to_add, ignore_index = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = [\"SUPPORTS\", \"REFUTES\", \"NOT_ENOUGH_INFO\", \"DISPUTED\"]\n",
    "label_map = {\"SUPPORTS\":0, \"REFUTES\":1, \"NOT_ENOUGH_INFO\":2, \"DISPUTED\":3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_data(claims,evidence):\n",
    "    X = pd.DataFrame(columns=['claim_id','text','num_evidences','evidence_ids'])\n",
    "    Y = []\n",
    "    # prepare text: <cls> claim text <sep> evidence_1 text <sep> evidence_2 text\n",
    "    for key, value in claims.items():\n",
    "        row_to_add = pd.DataFrame({\n",
    "            \"claim_id\" :[key],\n",
    "            \"text\": [\"<sep>\".join([\"<cls>\" +value['claim_text']] + [evidence[evd_id] for evd_id in value['evidences']])],\n",
    "            'num_evidences': len(value['evidences']),\n",
    "            'evidence_ids': [value['evidences']]\n",
    "        })\n",
    "        Y.append(value['claim_label'])\n",
    "        X = X.append(row_to_add, ignore_index = True)\n",
    "    X_list = X['text'].values\n",
    "    Y = list(map(lambda x: label_map[x], Y))\n",
    "    return X, X_list, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_X_only(claims, evidence):\n",
    "    X = pd.DataFrame(columns=['claim_id','text','num_evidences','evidence_ids'])\n",
    "\n",
    "    # prepare text: <cls> claim text <sep> evidence_1 text <sep> evidence_2 text\n",
    "    for key, value in claims.items():\n",
    "        row_to_add = pd.DataFrame({\n",
    "            \"claim_id\" :[key],\n",
    "            \"text\": [\"<sep>\".join([\"<cls>\" +value['claim_text']] + [evidence[evd_id] for evd_id in value['evidences']])],\n",
    "            'num_evidences': len(value['evidences']),\n",
    "            'evidence_ids': [value['evidences']]\n",
    "        })\n",
    "        X = X.append(row_to_add, ignore_index = True)\n",
    "    X_list = X['text'].values\n",
    "    \n",
    "    return X, X_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, train_X, train_y = reconstruct_data(train_claims,evidence)\n",
    "dev_df_true, dev_X_true, dev_y_true = reconstruct_data(dev_claims,evidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_df_pred, dev_X_pred = reconstruct_X_only(dev_pred,evidence)\n",
    "test_df, test_X = reconstruct_X_only(test_claims_pred,evidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
